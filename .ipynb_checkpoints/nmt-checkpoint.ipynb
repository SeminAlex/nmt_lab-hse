{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import cPickle as pickle\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "readed en0\n",
      "readed es0\n",
      "readed en1\n",
      "readed es1\n",
      "readed en2\n",
      "readed es2\n",
      "readed en3\n",
      "readed es3\n"
     ]
    }
   ],
   "source": [
    "#dataRead\n",
    "\n",
    "en_sentences = []\n",
    "es_sentences = []\n",
    "\n",
    "for i in range(4):\n",
    "    with open(\"dataset/europarl-v7.es-en-\" + str(i) +\".en\", 'r') as en_file:\n",
    "        for en_line in en_file:\n",
    "            en_sentences.append(en_line)\n",
    "    print \"readed en\" + str(i)\n",
    "    with open(\"dataset/europarl-v7.es-en-\" + str(i) +\".es\", 'r') as es_file:\n",
    "        for es_line in es_file:\n",
    "            es_sentences.append(es_line)\n",
    "    print \"readed es\" + str(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apart from anything else, they divisively create social problems for workers in the shipping industry and residents of island regions.\n",
      "\n",
      "Aparte de todo, crean, generando discrepancias, problemas sociales para los trabajadores del sector naviero y los residentes de las regiones insulares.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "index = 999999\n",
    "print en_sentences[index]\n",
    "print es_sentences[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DataPreparation\n",
    "def create_dataset(source_sentences,target_sentences):\n",
    "    source_vocab_dict = Counter(word.strip(',.\" ;:)(][?!') for sentence in source_sentences for word in sentence.split())\n",
    "    target_vocab_dict = Counter(word.strip(',.\" ;:)(][?!') for sentence in target_sentences for word in sentence.split())\n",
    "\n",
    "    source_vocab = map(lambda x: x[0], sorted(source_vocab_dict.items(), key = lambda x: -x[1]))\n",
    "    target_vocab = map(lambda x: x[0], sorted(target_vocab_dict.items(), key = lambda x: -x[1]))\n",
    "    \n",
    "    source_vocab = source_vocab[:20000]\n",
    "    target_vocab = target_vocab[:30000]\n",
    "    \n",
    "    start_idx = 2\n",
    "    source_word2idx = dict([(word, idx+start_idx) for idx, word in enumerate(source_vocab)])\n",
    "    source_word2idx['<ukn>'] = 0\n",
    "    source_word2idx['<pad>'] = 1\n",
    "    source_idx2word = dict([(idx, word) for word, idx in source_word2idx.iteritems()])\n",
    "    \n",
    "    start_idx = 4\n",
    "    target_word2idx = dict([(word, idx+start_idx) for idx, word in enumerate(target_vocab)])\n",
    "    target_word2idx['<ukn>'] = 0\n",
    "    target_word2idx['<go>']  = 1\n",
    "    target_word2idx['<eos>'] = 2\n",
    "    target_word2idx['<pad>'] = 3\n",
    "    \n",
    "    target_idx2word = dict([(idx, word) for word, idx in target_word2idx.iteritems()])\n",
    "    x = [[source_word2idx.get(word.strip(',.\" ;:)(][?!'), 0) for word in sentence.split()] for sentence in source_sentences]\n",
    "    y = [[target_word2idx.get(word.strip(',.\" ;:)(][?!'), 0) for word in sentence.split()] for sentence in target_sentences]\n",
    "    \n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        n1 = len(x[i])\n",
    "        n2 = len(y[i])\n",
    "        n = n1 if n1 < n2 else n2 \n",
    "        if abs(n1 - n2) <= 0.3 * n:\n",
    "            if n1 <= 15 and n2 <= 15:\n",
    "                X.append(x[i])\n",
    "                Y.append(y[i])\n",
    "    return X, Y, source_word2idx, source_idx2word, source_vocab, target_word2idx, target_idx2word, target_vocab\n",
    "\n",
    "def save_dataset(file_path, obj):\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump(obj, f, -1)\n",
    "\n",
    "def read_dataset(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#en_sentences = ['hello my friend', 'we need to reboot the server']\n",
    "#es_sentences = ['hola mi amigo', 'necesitamos reiniciar el servidor']\n",
    "save_dataset('./data.pkl', create_dataset(en_sentences, es_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset\n",
    "X, Y, en_word2idx, en_idx2word, en_vocab, es_word2idx, es_idx2word, es_vocab = read_dataset('data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence in English - encoded: [8425, 3, 2, 1695]\n",
      "Sentence in Spanish - encoded: [10624, 13, 575, 4, 1420]\n",
      "Decoded:\n",
      "------------------------\n",
      "Resumption of the session \n",
      "\n",
      "Reanudación del período de sesiones\n"
     ]
    }
   ],
   "source": [
    "#CHECK THAT WORKs\n",
    "print 'Sentence in English - encoded:', X[0]\n",
    "print 'Sentence in Spanish - encoded:', Y[0]\n",
    "print 'Decoded:\\n------------------------'\n",
    "\n",
    "for i in range(len(X[0])):\n",
    "    print en_idx2word[X[0][i]],\n",
    "    \n",
    "print '\\n'\n",
    "\n",
    "for i in range(len(Y[0])):\n",
    "    print es_idx2word[Y[0][i]],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# data processing\n",
    "\n",
    "# data padding\n",
    "def data_padding(x, y, length = 15):\n",
    "    for i in range(len(x)):\n",
    "        x[i] = x[i] + (length - len(x[i])) * [en_word2idx['<pad>']]\n",
    "        y[i] = [es_word2idx['<go>']] + y[i] + [es_word2idx['<eos>']] + (length-len(y[i])) * [es_word2idx['<pad>']]\n",
    "\n",
    "data_padding(X, Y)\n",
    "print X\n",
    "\n",
    "# data splitting\n",
    "X_train,  X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.1)\n",
    "\n",
    "del X\n",
    "del Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a model\n",
    "\n",
    "input_seq_len = 15\n",
    "output_seq_len = 17\n",
    "en_vocab_size = len(en_vocab) + 2 # + <pad>, <ukn>\n",
    "es_vocab_size = len(es_vocab) + 4 # + <pad>, <ukn>, <eos>, <go>\n",
    "\n",
    "# placeholders\n",
    "encoder_inputs = [tf.placeholder(dtype = tf.int32, shape = [None], name = 'encoder{}'.format(i)) for i in range(input_seq_len)]\n",
    "decoder_inputs = [tf.placeholder(dtype = tf.int32, shape = [None], name = 'decoder{}'.format(i)) for i in range(output_seq_len)]\n",
    "\n",
    "targets = [decoder_inputs[i+1] for i in range(output_seq_len-1)]\n",
    "# add one more target\n",
    "targets.append(tf.placeholder(dtype = tf.int32, shape = [None], name = 'last_target'))\n",
    "target_weights = [tf.placeholder(dtype = tf.float32, shape = [None], name = 'target_w{}'.format(i)) for i in range(output_seq_len)]\n",
    "\n",
    "# output projection\n",
    "size = 512\n",
    "w_t = tf.get_variable('proj_w', [es_vocab_size, size], tf.float32)\n",
    "b = tf.get_variable('proj_b', [es_vocab_size], tf.float32)\n",
    "w = tf.transpose(w_t)\n",
    "output_projection = (w, b)\n",
    "\n",
    "outputs, states = tf.contrib.legacy_seq2seq.embedding_attention_seq2seq(\n",
    "                                            encoder_inputs,\n",
    "                                            decoder_inputs,\n",
    "                                            tf.contrib.rnn.BasicLSTMCell(size),\n",
    "                                            num_encoder_symbols = en_vocab_size,\n",
    "                                            num_decoder_symbols = es_vocab_size,\n",
    "                                            embedding_size = 100,\n",
    "                                            feed_previous = False,\n",
    "                                            output_projection = output_projection,\n",
    "                                            dtype = tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our loss function\n",
    "\n",
    "# sampled softmax loss - returns: A batch_size 1-D tensor of per-example sampled softmax losses\n",
    "def sampled_loss(labels, logits):\n",
    "    return tf.nn.sampled_softmax_loss(\n",
    "                        weights = w_t,\n",
    "                        biases = b,\n",
    "                        labels = tf.reshape(labels, [-1, 1]),\n",
    "                        inputs = logits,\n",
    "                        num_sampled = 512,\n",
    "                        num_classes = es_vocab_size)\n",
    "\n",
    "# Weighted cross-entropy loss for a sequence of logits\n",
    "loss = tf.contrib.legacy_seq2seq.sequence_loss(outputs, targets, target_weights, softmax_loss_function = sampled_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define some helper functions\n",
    "\n",
    "# simple softmax function\n",
    "def softmax(x):\n",
    "    n = np.max(x)\n",
    "    e_x = np.exp(x - n)\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "# feed data into placeholders\n",
    "def feed_dict(x, y, batch_size = 64):\n",
    "    feed = {}\n",
    "    \n",
    "    idxes = np.random.choice(len(x), size = batch_size, replace = False)\n",
    "    \n",
    "    for i in range(input_seq_len):\n",
    "        feed[encoder_inputs[i].name] = np.array([x[j][i] for j in idxes], dtype = np.int32)\n",
    "        \n",
    "    for i in range(output_seq_len):\n",
    "        feed[decoder_inputs[i].name] = np.array([y[j][i] for j in idxes], dtype = np.int32)\n",
    "        \n",
    "    feed[targets[len(targets)-1].name] = np.full(shape = [batch_size], fill_value = es_word2idx['<pad>'], dtype = np.int32)\n",
    "    \n",
    "    for i in range(output_seq_len-1):\n",
    "        batch_weights = np.ones(batch_size, dtype = np.float32)\n",
    "        target = feed[decoder_inputs[i+1].name]\n",
    "        for j in range(batch_size):\n",
    "            if target[j] == es_word2idx['<pad>']:\n",
    "                batch_weights[j] = 0.0\n",
    "        feed[target_weights[i].name] = batch_weights\n",
    "        \n",
    "    feed[target_weights[output_seq_len-1].name] = np.zeros(batch_size, dtype = np.float32)\n",
    "    \n",
    "    return feed\n",
    "\n",
    "# decode output sequence\n",
    "def decode_output(output_seq):\n",
    "    words = []\n",
    "    for i in range(output_seq_len):\n",
    "        smax = softmax(output_seq[i])\n",
    "        idx = np.argmax(smax)\n",
    "        words.append(es_idx2word[idx])\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ops and hyperparameters\n",
    "learning_rate = 5e-3\n",
    "batch_size = 64\n",
    "steps = 10000\n",
    "\n",
    "# ops for projecting outputs\n",
    "outputs_proj = [tf.matmul(outputs[i], output_projection[0]) + output_projection[1] for i in range(output_seq_len)]\n",
    "\n",
    "# training op\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "# init op\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# forward step\n",
    "def forward_step(sess, feed):\n",
    "    output_sequences = sess.run(outputs_proj, feed_dict = feed)\n",
    "    return output_sequences\n",
    "\n",
    "# training step\n",
    "def backward_step(sess, feed):\n",
    "    sess.run(optimizer, feed_dict = feed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------TRAINING------------------\n",
      "step: 0, loss: 8.92558860779\n",
      "step: 4, loss: 9.06633377075\n",
      "step: 9, loss: 9.02219867706\n",
      "step: 14, loss: 9.09511947632\n",
      "step: 19, loss: 9.00766563416\n",
      "Checkpoint is saved\n",
      "step: 24, loss: 9.03717803955\n",
      "step: 29, loss: 9.01612567902\n",
      "step: 34, loss: 8.99985313416\n",
      "step: 39, loss: 8.96087741852\n",
      "Checkpoint is saved\n",
      "step: 44, loss: 8.87794685364\n",
      "step: 49, loss: 8.88743305206\n",
      "step: 54, loss: 8.74408435822\n",
      "step: 59, loss: 8.054728508\n",
      "Checkpoint is saved\n",
      "step: 64, loss: 7.58675718307\n",
      "step: 69, loss: 6.99651384354\n",
      "step: 74, loss: 6.85336017609\n",
      "step: 79, loss: 6.15587091446\n",
      "Checkpoint is saved\n",
      "step: 84, loss: 6.20940351486\n",
      "step: 89, loss: 6.20745563507\n",
      "step: 94, loss: 6.43007087708\n",
      "step: 99, loss: 6.10704040527\n",
      "Checkpoint is saved\n",
      "step: 104, loss: 5.55369186401\n",
      "step: 109, loss: 5.6913599968\n",
      "step: 114, loss: 5.7345533371\n",
      "step: 119, loss: 6.28576087952\n",
      "Checkpoint is saved\n",
      "step: 124, loss: 5.48876857758\n",
      "step: 129, loss: 7.00510120392\n",
      "step: 134, loss: 5.30073070526\n",
      "step: 139, loss: 5.23182344437\n",
      "Checkpoint is saved\n",
      "step: 144, loss: 5.46565628052\n",
      "step: 149, loss: 6.43339300156\n",
      "step: 154, loss: 4.98730516434\n",
      "step: 159, loss: 4.7909784317\n",
      "Checkpoint is saved\n",
      "step: 164, loss: 4.98559999466\n",
      "step: 169, loss: 5.24494838715\n",
      "step: 174, loss: 5.08930587769\n",
      "step: 179, loss: 5.30606937408\n",
      "Checkpoint is saved\n",
      "step: 184, loss: 4.8882856369\n",
      "step: 189, loss: 4.85701990128\n",
      "step: 194, loss: 5.05048274994\n",
      "step: 199, loss: 4.53820610046\n",
      "Checkpoint is saved\n",
      "step: 204, loss: 4.77499771118\n",
      "step: 209, loss: 4.34143924713\n",
      "step: 214, loss: 4.53493595123\n",
      "step: 219, loss: 4.2360086441\n",
      "Checkpoint is saved\n",
      "step: 224, loss: 4.43618822098\n",
      "step: 229, loss: 4.53355693817\n",
      "step: 234, loss: 4.38798236847\n",
      "step: 239, loss: 4.1531829834\n",
      "Checkpoint is saved\n",
      "step: 244, loss: 3.71070742607\n",
      "step: 249, loss: 3.86033940315\n",
      "step: 254, loss: 4.03124904633\n",
      "step: 259, loss: 3.67005372047\n",
      "Checkpoint is saved\n",
      "step: 264, loss: 3.47524404526\n",
      "step: 269, loss: 3.88377833366\n",
      "step: 274, loss: 4.00588512421\n",
      "step: 279, loss: 3.13337755203\n",
      "Checkpoint is saved\n",
      "step: 284, loss: 3.68928909302\n",
      "step: 289, loss: 3.33679413795\n",
      "step: 294, loss: 3.28311753273\n",
      "step: 299, loss: 3.39050579071\n",
      "Checkpoint is saved\n",
      "step: 304, loss: 3.14247965813\n",
      "step: 309, loss: 3.54907226562\n",
      "step: 314, loss: 3.38231134415\n",
      "step: 319, loss: 3.02172493935\n",
      "Checkpoint is saved\n",
      "step: 324, loss: 3.58394551277\n",
      "step: 329, loss: 3.03760695457\n",
      "step: 334, loss: 2.83631467819\n",
      "step: 339, loss: 3.39379858971\n",
      "Checkpoint is saved\n",
      "step: 344, loss: 2.68682146072\n",
      "step: 349, loss: 3.39361667633\n",
      "step: 354, loss: 2.75686788559\n",
      "step: 359, loss: 3.04542708397\n",
      "Checkpoint is saved\n",
      "step: 364, loss: 2.9369392395\n",
      "step: 369, loss: 3.0882768631\n",
      "step: 374, loss: 2.53012752533\n",
      "step: 379, loss: 3.01166653633\n",
      "Checkpoint is saved\n",
      "step: 384, loss: 2.65624809265\n",
      "step: 389, loss: 2.62030220032\n",
      "step: 394, loss: 2.93495130539\n",
      "step: 399, loss: 2.95530700684\n",
      "Checkpoint is saved\n",
      "step: 404, loss: 2.67181015015\n",
      "step: 409, loss: 2.75757265091\n",
      "step: 414, loss: 2.50515222549\n",
      "step: 419, loss: 2.14571714401\n",
      "Checkpoint is saved\n",
      "step: 424, loss: 2.70251631737\n",
      "step: 429, loss: 2.48342728615\n",
      "step: 434, loss: 2.39858865738\n",
      "step: 439, loss: 2.39453959465\n",
      "Checkpoint is saved\n",
      "step: 444, loss: 2.30675601959\n",
      "step: 449, loss: 2.34642696381\n",
      "step: 454, loss: 2.43846321106\n",
      "step: 459, loss: 1.95679831505\n",
      "Checkpoint is saved\n",
      "step: 464, loss: 2.61027479172\n",
      "step: 469, loss: 2.35970211029\n",
      "step: 474, loss: 2.63497304916\n",
      "step: 479, loss: 2.22166967392\n",
      "Checkpoint is saved\n",
      "step: 484, loss: 2.12408304214\n",
      "step: 489, loss: 2.30282688141\n",
      "step: 494, loss: 2.47863578796\n",
      "step: 499, loss: 2.08217477798\n",
      "Checkpoint is saved\n",
      "step: 504, loss: 1.96213269234\n",
      "step: 509, loss: 2.37655115128\n",
      "step: 514, loss: 2.25188207626\n",
      "step: 519, loss: 2.29673981667\n",
      "Checkpoint is saved\n",
      "step: 524, loss: 2.11882948875\n",
      "step: 529, loss: 1.85768198967\n",
      "step: 534, loss: 2.08620882034\n",
      "step: 539, loss: 2.00714302063\n",
      "Checkpoint is saved\n",
      "step: 544, loss: 2.00926733017\n",
      "step: 549, loss: 2.10951495171\n",
      "step: 554, loss: 2.04903626442\n",
      "step: 559, loss: 1.92104995251\n",
      "Checkpoint is saved\n",
      "step: 564, loss: 1.84745180607\n",
      "step: 569, loss: 2.15136814117\n",
      "step: 574, loss: 2.21448612213\n",
      "step: 579, loss: 2.00668525696\n",
      "Checkpoint is saved\n",
      "step: 584, loss: 1.72738480568\n",
      "step: 589, loss: 1.79770970345\n",
      "step: 594, loss: 1.48245179653\n",
      "step: 599, loss: 2.32090616226\n",
      "Checkpoint is saved\n",
      "step: 604, loss: 1.90012955666\n",
      "step: 609, loss: 1.72993135452\n",
      "step: 614, loss: 1.85435211658\n",
      "step: 619, loss: 1.81974363327\n",
      "Checkpoint is saved\n",
      "step: 624, loss: 2.12047338486\n",
      "step: 629, loss: 1.86223340034\n",
      "step: 634, loss: 1.81781816483\n",
      "step: 639, loss: 1.4887638092\n",
      "Checkpoint is saved\n",
      "step: 644, loss: 1.69611167908\n",
      "step: 649, loss: 1.8579313755\n",
      "step: 654, loss: 1.59525465965\n",
      "step: 659, loss: 1.65029239655\n",
      "Checkpoint is saved\n",
      "step: 664, loss: 1.88992774487\n",
      "step: 669, loss: 1.48774027824\n",
      "step: 674, loss: 1.78937482834\n",
      "step: 679, loss: 1.48080158234\n",
      "Checkpoint is saved\n",
      "step: 684, loss: 1.73909592628\n",
      "step: 689, loss: 1.74945163727\n",
      "step: 694, loss: 1.62268817425\n",
      "step: 699, loss: 1.64177691936\n",
      "Checkpoint is saved\n",
      "step: 704, loss: 1.87202644348\n",
      "step: 709, loss: 1.59037351608\n",
      "step: 714, loss: 1.22454500198\n",
      "step: 719, loss: 1.75518262386\n",
      "Checkpoint is saved\n",
      "step: 724, loss: 1.51536798477\n",
      "step: 729, loss: 1.5798561573\n",
      "step: 734, loss: 1.66278779507\n",
      "step: 739, loss: 1.60547983646\n",
      "Checkpoint is saved\n",
      "step: 744, loss: 1.26272690296\n",
      "step: 749, loss: 1.3281416893\n",
      "step: 754, loss: 1.77242875099\n",
      "step: 759, loss: 1.40916824341\n",
      "Checkpoint is saved\n",
      "step: 764, loss: 1.32357311249\n",
      "step: 769, loss: 1.67590343952\n",
      "step: 774, loss: 1.27986741066\n",
      "step: 779, loss: 1.67074275017\n",
      "Checkpoint is saved\n",
      "step: 784, loss: 1.44665443897\n",
      "step: 789, loss: 1.70748722553\n",
      "step: 794, loss: 1.4569863081\n",
      "step: 799, loss: 1.36141705513\n",
      "Checkpoint is saved\n",
      "step: 804, loss: 1.34870111942\n",
      "step: 809, loss: 1.53612649441\n",
      "step: 814, loss: 1.74871325493\n",
      "step: 819, loss: 1.34902250767\n",
      "Checkpoint is saved\n",
      "step: 824, loss: 1.28283631802\n",
      "step: 829, loss: 1.70771515369\n",
      "step: 834, loss: 1.26306557655\n",
      "step: 839, loss: 1.46560657024\n",
      "Checkpoint is saved\n",
      "step: 844, loss: 1.40300035477\n",
      "step: 849, loss: 1.42076051235\n",
      "step: 854, loss: 1.6110162735\n",
      "step: 859, loss: 1.3940885067\n",
      "Checkpoint is saved\n",
      "step: 864, loss: 1.49028003216\n",
      "step: 869, loss: 1.48228907585\n",
      "step: 874, loss: 1.27660155296\n",
      "step: 879, loss: 1.3478474617\n",
      "Checkpoint is saved\n",
      "step: 884, loss: 1.35645127296\n",
      "step: 889, loss: 1.66115295887\n",
      "step: 894, loss: 1.44292759895\n",
      "step: 899, loss: 1.36616396904\n",
      "Checkpoint is saved\n",
      "step: 904, loss: 1.19458460808\n",
      "step: 909, loss: 1.54108548164\n",
      "step: 914, loss: 1.48550570011\n",
      "step: 919, loss: 1.30170202255\n",
      "Checkpoint is saved\n",
      "step: 924, loss: 1.4319126606\n",
      "step: 929, loss: 1.36166334152\n",
      "step: 934, loss: 1.43337917328\n",
      "step: 939, loss: 1.20651936531\n",
      "Checkpoint is saved\n",
      "step: 944, loss: 1.28029990196\n",
      "step: 949, loss: 1.26227092743\n",
      "step: 954, loss: 1.1176970005\n",
      "step: 959, loss: 1.31189095974\n",
      "Checkpoint is saved\n",
      "step: 964, loss: 1.14318132401\n",
      "step: 969, loss: 1.17951178551\n",
      "step: 974, loss: 1.28048491478\n",
      "step: 979, loss: 1.38820624352\n",
      "Checkpoint is saved\n",
      "step: 984, loss: 1.36367058754\n",
      "step: 989, loss: 1.1482656002\n",
      "step: 994, loss: 1.14171481133\n",
      "step: 999, loss: 1.32122087479\n",
      "Checkpoint is saved\n",
      "Training time for 1000 steps: 457.794358015s\n"
     ]
    }
   ],
   "source": [
    "# let's train the model\n",
    "\n",
    "# we will use this list to plot losses through steps\n",
    "losses = []\n",
    "\n",
    "# save a checkpoint so we can restore the model later \n",
    "saver = tf.train.Saver()\n",
    "\n",
    "print '------------------TRAINING------------------'\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    t = time.time()\n",
    "    for step in range(steps):\n",
    "        feed = feed_dict(X_train, Y_train)\n",
    "            \n",
    "        backward_step(sess, feed)\n",
    "        \n",
    "        if step % 5 == 4 or step == 0:\n",
    "            loss_value = sess.run(loss, feed_dict = feed)\n",
    "            print 'step: {}, loss: {}'.format(step, loss_value)\n",
    "            losses.append(loss_value)\n",
    "        \n",
    "        if step % 20 == 19:\n",
    "            saver.save(sess, 'checkpoints/', global_step=step)\n",
    "            print 'Checkpoint is saved'\n",
    "            \n",
    "    print 'Training time for {} steps: {}s'.format(steps, time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbEAAAEkCAYAAAChew9BAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmIiI5K0/DGDHyIB2YiQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff08cd3c3d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot losses\n",
    "\n",
    "with plt.style.context('fivethirtyeight'):\n",
    "    plt.plot(losses, linewidth = 1)\n",
    "    plt.xlabel('Steps')\n",
    "    plt.ylabel('Losses')\n",
    "    plt.ylim((0, 12))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/-999\n",
      "1.\n",
      "--------------------------------\n",
      "reboot the server\n",
      "<ukn> la <ukn> \n",
      "--------------------------------\n",
      "2.\n",
      "--------------------------------\n",
      "What' s your name\n",
      "<ukn> su nombre de su intervención \n",
      "--------------------------------\n",
      "3.\n",
      "--------------------------------\n",
      "My name is\n",
      "Mi nombre es \n",
      "--------------------------------\n",
      "4.\n",
      "--------------------------------\n",
      "What are you doing\n",
      "¿Qué qué qué qué \n",
      "--------------------------------\n",
      "5.\n",
      "--------------------------------\n",
      "I am reading a book\n",
      "Estoy recibido una serie \n",
      "--------------------------------\n",
      "6.\n",
      "--------------------------------\n",
      "How are you\n",
      "¿Cómo \n",
      "--------------------------------\n",
      "7.\n",
      "--------------------------------\n",
      "I am good\n",
      "Estoy buena \n",
      "--------------------------------\n",
      "8.\n",
      "--------------------------------\n",
      "Do you speak English\n",
      "<ukn> usted usted \n",
      "--------------------------------\n",
      "9.\n",
      "--------------------------------\n",
      "What time is it\n",
      "¿Qué tiempo qué es lo \n",
      "--------------------------------\n",
      "10.\n",
      "--------------------------------\n",
      "Hi\n",
      "<ukn> \n",
      "--------------------------------\n",
      "11.\n",
      "--------------------------------\n",
      "Goodbye\n",
      "<ukn> \n",
      "--------------------------------\n",
      "12.\n",
      "--------------------------------\n",
      "Yes\n",
      "Sí \n",
      "--------------------------------\n",
      "13.\n",
      "--------------------------------\n",
      "No\n",
      "No \n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "# let's test the model\n",
    "\n",
    "with tf.Graph().as_default():\n",
    "    \n",
    "    # placeholders\n",
    "    encoder_inputs = [tf.placeholder(dtype = tf.int32, shape = [None], name = 'encoder{}'.format(i)) for i in range(input_seq_len)]\n",
    "    decoder_inputs = [tf.placeholder(dtype = tf.int32, shape = [None], name = 'decoder{}'.format(i)) for i in range(output_seq_len)]\n",
    "\n",
    "    # output projection\n",
    "    size = 512\n",
    "    w_t = tf.get_variable('proj_w', [es_vocab_size, size], tf.float32)\n",
    "    b = tf.get_variable('proj_b', [es_vocab_size], tf.float32)\n",
    "    w = tf.transpose(w_t)\n",
    "    output_projection = (w, b)\n",
    "    \n",
    "    # change the model so that output at time t can be fed as input at time t+1\n",
    "    outputs, states = tf.contrib.legacy_seq2seq.embedding_attention_seq2seq(\n",
    "                                                encoder_inputs,\n",
    "                                                decoder_inputs,\n",
    "                                                tf.contrib.rnn.BasicLSTMCell(size),\n",
    "                                                num_encoder_symbols = en_vocab_size,\n",
    "                                                num_decoder_symbols = es_vocab_size,\n",
    "                                                embedding_size = 100,\n",
    "                                                feed_previous = True, # <-----this is changed----->\n",
    "                                                output_projection = output_projection,\n",
    "                                                dtype = tf.float32)\n",
    "    \n",
    "    # ops for projecting outputs\n",
    "    outputs_proj = [tf.matmul(outputs[i], output_projection[0]) + output_projection[1] for i in range(output_seq_len)]\n",
    "\n",
    "    # let's translate these sentences     \n",
    "    en_sentences = [\"reboot the server\", \"What' s your name\", 'My name is', 'What are you doing', 'I am reading a book',\\\n",
    "                    'How are you', 'I am good', 'Do you speak English', 'What time is it', 'Hi', 'Goodbye', 'Yes', 'No']\n",
    "    en_sentences_encoded = [[en_word2idx.get(word, 0) for word in en_sentence.split()] for en_sentence in en_sentences]\n",
    "    \n",
    "    # padding to fit encoder input\n",
    "    for i in range(len(en_sentences_encoded)):\n",
    "        en_sentences_encoded[i] += (15 - len(en_sentences_encoded[i])) * [en_word2idx['<pad>']]\n",
    "    \n",
    "    # restore all variables - use the last checkpoint saved\n",
    "    saver = tf.train.Saver()\n",
    "    path = tf.train.latest_checkpoint('checkpoints')\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        # restore\n",
    "        saver.restore(sess, path)\n",
    "        \n",
    "        # feed data into placeholders\n",
    "        feed = {}\n",
    "        for i in range(input_seq_len):\n",
    "            feed[encoder_inputs[i].name] = np.array([en_sentences_encoded[j][i] for j in range(len(en_sentences_encoded))], dtype = np.int32)\n",
    "            \n",
    "        feed[decoder_inputs[0].name] = np.array([es_word2idx['<go>']] * len(en_sentences_encoded), dtype = np.int32)\n",
    "        \n",
    "        # translate\n",
    "        output_sequences = sess.run(outputs_proj, feed_dict = feed)\n",
    "        \n",
    "        # decode seq.\n",
    "        for i in range(len(en_sentences_encoded)):\n",
    "            print '{}.\\n--------------------------------'.format(i+1)\n",
    "            ouput_seq = [output_sequences[j][i] for j in range(output_seq_len)]\n",
    "            #decode output sequence\n",
    "            words = decode_output(ouput_seq)\n",
    "        \n",
    "            print en_sentences[i]\n",
    "            for i in range(len(words)):\n",
    "                if words[i] not in ['<eos>', '<pad>', '<go>']:\n",
    "                    print words[i],\n",
    "            \n",
    "            print '\\n--------------------------------'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-py2",
   "language": "python",
   "name": "tensorflow-py2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
